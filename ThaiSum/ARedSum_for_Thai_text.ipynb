{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ARedSum_for_Thai_text.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUVqEhF2FvJL"
      },
      "source": [
        "This notebook presents how to train ARedsum models, the extractive summarization based models, on ThaiSum dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1YAr-EtEqBp"
      },
      "source": [
        "# Introduction to ARedSumSentRank\n",
        "Cite from their paper's abstract [\"AREDSUM: Adaptive Redundancy-Aware Iterative Sentence Ranking for Extractive Document Summarization\"](https://arxiv.org/abs/2004.06176) introduced by Keping Bi, Rahul Jha, W. Bruce Croft, Asli Celikyilmaz. (2020), \n",
        "\"...Building on the state-of-the-art encoding methods for summarization, we present two adaptive learning models: AREDSUM-SEQ that jointly considers salience and novelty during sentence selection; and a two-step AREDSUM-CTX that scores salience first, then learns to balance salience and redundancy, enabling the measurement of the impact of each aspect....\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1lgD7AnF5rv"
      },
      "source": [
        "# Install requirements "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j4OEqEyGMx0"
      },
      "source": [
        "%%capture\n",
        "!git clone https://github.com/nakhunchumpolsathien/ThaiSum.git"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df7kmAY9KBVP"
      },
      "source": [
        "%%capture \n",
        "!pip install torch==1.1.0 torchvision==0.3.0\n",
        "!pip install -q pyrouge\n",
        "!pip install -q pytorch_transformers\n",
        "!pip install -q tensorboardX\n",
        "!pip install -q pyrouge\n",
        "!pip install pytorch_pretrained_bert\n",
        "!pyrouge_set_rouge_path \"/content/ThaiSum/BertSum/ROUGE-1.5.5\"\n",
        "!apt update\n",
        "!apt install -q libxml-parser-perl\n",
        "%cd \"/content/ThaiSum/BertSum/ROUGE-1.5.5/data\"\n",
        "!perl WordNet-2.0-Exceptions/buildExeptionDB.pl ./WordNet-2.0-Exceptions ./smart_common_words.txt ./WordNet-2.0.exc.db"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6CdVosLyeA1"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiSh3mH4ypEG",
        "outputId": "df750735-d76d-4848-d98d-e4da08e49fe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd '/content/ThaiSum/ARedSum/src'\n",
        "!python preprocess.py -mode format_to_bert -raw_path \"/content/ThaiSum/ARedSum/js_data\" -save_path \"/content/ThaiSum/ARedSum/bert_data\" -oracle_mode greedy -n_cpus 1 -log_file ../logs/preprocess.log"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ThaiSum/ARedSum/src\n",
            "[2020-11-14 08:14:51,896 INFO] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt not found in cache, downloading to /tmp/tmpl3nov12u\n",
            "100% 995526/995526 [00:00<00:00, 5627327.20B/s]\n",
            "[2020-11-14 08:14:52,225 INFO] copying /tmp/tmpl3nov12u to cache at /root/.pytorch_pretrained_bert/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
            "[2020-11-14 08:14:52,227 INFO] creating metadata file for /root/.pytorch_pretrained_bert/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
            "[2020-11-14 08:14:52,227 INFO] removing temp file /tmp/tmpl3nov12u\n",
            "[2020-11-14 08:14:52,228 INFO] loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /root/.pytorch_pretrained_bert/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
            "[2020-11-14 08:14:52,363 INFO] Processing /content/ThaiSum/ARedSum/js_data/thaisum.train.0.json\n",
            "[2020-11-14 08:15:03,192 INFO] Saving to /content/ThaiSum/ARedSum/bert_data/thaisum.train.0.bert.pt\n",
            "[2020-11-14 08:15:04,111 INFO] loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at /root/.pytorch_pretrained_bert/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n",
            "[2020-11-14 08:15:04,251 INFO] Processing /content/ThaiSum/ARedSum/js_data/thaisum.test.0.json\n",
            "[2020-11-14 08:15:04,288 INFO] Saving to /content/ThaiSum/ARedSum/bert_data/thaisum.test.0.bert.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b_K3hQqzWqN"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80VDsXvGzbPk",
        "outputId": "61805acd-6d19-463f-8a61-e822c0c72243",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train (ARedSum-Base) Train a Salience Ranker\n",
        "!python train.py -bert_data_path \"/content/ThaiSum/ARedSum/bert_data/thaisum\" -visible_gpus 0 -gpu_ranks 0 -accum_count 2 -report_every 50 -save_checkpoint_steps 2000 -decay_method noam -mode train -model_name base -label_format soft -result_path \"/content/ThaiSum/ARedSum/results/aredsum_base\" -model_path \"/content/ThaiSum/ARedSum/model_checkpoint/ARedSum_base\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-11-14 08:21:49,629 INFO] Device ID 0\n",
            "[2020-11-14 08:21:49,629 INFO] Device cuda\n",
            "[2020-11-14 08:21:49,802 INFO] loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased.tar.gz from cache at ../temp/731c19ddf94e294e00ec1ba9a930c69cc2a0fd489b25d3d691373fae4c0986bd.4e367b0d0155d801930846bb6ed98f8a7c23e0ded37888b29caa37009a40c7b9\n",
            "[2020-11-14 08:21:49,803 INFO] extracting archive file ../temp/731c19ddf94e294e00ec1ba9a930c69cc2a0fd489b25d3d691373fae4c0986bd.4e367b0d0155d801930846bb6ed98f8a7c23e0ded37888b29caa37009a40c7b9 to temp dir /tmp/tmplzetjsc0\n",
            "[2020-11-14 08:21:56,188 INFO] Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "[2020-11-14 08:22:04,457 INFO] Summarizer(\n",
            "  (bert): Bert(\n",
            "    (model): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): BertLayerNorm()\n",
            "        (dropout): Dropout(p=0.1)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (transformer_encoder): TransformerInterEncoder(\n",
            "    (pos_emb): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1)\n",
            "    )\n",
            "    (transformer_inter): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (softmax): Softmax()\n",
            "          (dropout): Dropout(p=0.1)\n",
            "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
            "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1)\n",
            "          (dropout_2): Dropout(p=0.1)\n",
            "        )\n",
            "        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (softmax): Softmax()\n",
            "          (dropout): Dropout(p=0.1)\n",
            "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
            "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1)\n",
            "          (dropout_2): Dropout(p=0.1)\n",
            "        )\n",
            "        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (encoder): PairwiseMLP(\n",
            "    (scorer): biLinearModel(\n",
            "      (bilinear): Bilinear(in1_features=768, in2_features=768, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "gpu_rank 0\n",
            "[2020-11-14 08:22:04,548 INFO] * number of parameters: 189473537\n",
            "[2020-11-14 08:22:04,548 INFO] Start training...\n",
            "[2020-11-14 08:22:04,620 INFO] Loading train dataset from /content/ThaiSum/ARedSum/bert_data/thaisum.train.0.bert.pt, number of examples: 1000\n",
            "[2020-11-14 08:22:04,620 INFO] input_batch_size:3000\n",
            "[2020-11-14 08:22:04,620 INFO] Current Epoch:0\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 393, in <module>\n",
            "    train(args, device_id)\n",
            "  File \"train.py\", line 298, in train\n",
            "    _, neg_valid_loss = trainer.train(train_iter_fct, args.train_steps)\n",
            "  File \"/content/ThaiSum/ARedSum/src/models/trainer.py\", line 182, in train\n",
            "    report_stats)\n",
            "  File \"/content/ThaiSum/ARedSum/src/models/trainer.py\", line 593, in _gradient_accumulation\n",
            "    sel_sent_hit_map=batch.hit_map)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/ThaiSum/ARedSum/src/models/model_builder.py\", line 144, in forward\n",
            "    top_vec = self.bert(x, segs, mask)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/ThaiSum/ARedSum/src/models/model_builder.py\", line 57, in forward\n",
            "    encoded_layers, _ = self.model(x, segs, attention_mask =mask)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/modeling.py\", line 733, in forward\n",
            "    output_all_encoded_layers=output_all_encoded_layers)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/modeling.py\", line 406, in forward\n",
            "    hidden_states = layer_module(hidden_states, attention_mask)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/modeling.py\", line 391, in forward\n",
            "    attention_output = self.attention(hidden_states, attention_mask)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/modeling.py\", line 349, in forward\n",
            "    self_output = self.self(input_tensor, attention_mask)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/modeling.py\", line 310, in forward\n",
            "    attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 60.00 MiB (GPU 0; 7.43 GiB total capacity; 6.58 GiB already allocated; 30.94 MiB free; 270.23 MiB cached)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrmnl_1A06MD"
      },
      "source": [
        "# Train (ARedSum-CTX) Train a Ranker for Selection\n",
        "!python train.py -fix_scorer -train_from /path/to/the/best/salience/ranker.pt -bert_data_path /path/to/cnndm_or_nyt50/bert_data/ -visible_gpus 2 -gpu_ranks 0 -accum_count 2 -report_every 50 -save_checkpoint_steps 2000 -decay_method noam -model_name ctx -max_epoch 2 -train_steps 50000 -label_format soft -use_rouge_label t -valid_by_rouge t -rand_input_thre 1.0 -temperature 20 -seg_count 30 -ngram_seg_count 20,20,20 -bilinear_out 20 -result_path /path/to/where/you/want/to/save/the/preidicted/summaries -model_path /path/to/where/you/want/to/save/the/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXQR2ZQ20ya1"
      },
      "source": [
        "# Train (ARedSum-SEQ) Train a Sequence Generation Model\n",
        "!python train.py -bert_data_path /path/to/cnndm_or_nyt50/bert_data/ -visible_gpus 2 -gpu_ranks 0 -accum_count 2 -report_every 50 -save_checkpoint_steps 2000 -decay_method noam -model_name seq -max_epoch 2 -train_steps 50000 -label_format soft -use_rouge_label t -valid_by_rouge t -rand_input_thre 0.8 -temperature 20 -result_path /path/to/where/you/want/to/save/the/preidicted/summaries -model_path /path/to/where/you/want/to/save/the/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH5e91Bu2Srv"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziscOITR2bGc"
      },
      "source": [
        "## Evaluate by ROUGE Score "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92Rw8-Qu2dJp",
        "outputId": "9f5ca98a-f3f2-42f9-a991-38e69c2da7b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluate ARedSum-Base \n",
        "!python train.py -bert_data_path \"/content/ThaiSum/ARedSum/bert_data/thaisum\" -visible_gpus 0 -gpu_ranks 0 -accum_count 2 -report_every 50 -save_checkpoint_steps 2000 -decay_method noam -mode test -model_name base -label_format soft -result_path \"/content/ThaiSum/ARedSum/results/aredsum_base\" -test_from \"/content/ThaiSum/ARedSum/model_checkpoint/ARedSum_base.pt\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2020-11-14 08:30:40,819 INFO] Loading checkpoint from /content/ThaiSum/ARedSum/model_checkpoint/ARedSum_base.pt\n",
            "Namespace(accum_count=2, aggr='last', batch_size=3000, bert_config_path='config/bert_config_uncased_base.json', bert_data_path='/content/ThaiSum/ARedSum/bert_data/thaisum', beta1=0.9, beta2=0.999, bilinear_out=10, block_trigram=True, dataset='', decay_method='noam', dropout=0.1, ff_size=2048, fix_scorer=False, gpu_ranks=[0], heads=8, hidden_size=128, inter_layers=2, label_format='soft', log_file='../logs/cnndm.log', loss='wsoftmax', lr=0.002, max_epoch=2, max_grad_norm=0, max_label_sent_count=3, mode='test', model_name='base', model_path='../models/', ngram_seg_count='20,20,20', optim='adam', param_init=0, param_init_glorot=True, rand_input_thre=1.0, recall_eval=False, report_every=50, report_precision=True, report_rouge=True, result_path='/content/ThaiSum/ARedSum/results/aredsum_base', rnn_size=512, salience_softmax=False, save_checkpoint_steps=2000, save_model_count=3, seed=666, seg_count=30, sent_sel_method='truth', temp_dir='../temp', temperature=20, test_all=False, test_from='/content/ThaiSum/ARedSum/model_checkpoint/ARedSum_base.pt', train_from='', train_steps=50000, use_doc=False, use_interval=True, use_rouge_label=False, valid_by_rouge=False, visible_gpus='0', warmup_steps=10000, world_size=1)\n",
            "gpu_rank 0\n",
            "[2020-11-14 08:30:49,653 INFO] * number of parameters: 189473537\n",
            "[2020-11-14 08:30:49,963 INFO] Loading test dataset from /content/ThaiSum/ARedSum/bert_data/thaisum.test.1.bert.pt, number of examples: 1000\n",
            "[2020-11-14 08:30:49,963 INFO] input_batch_size:3000\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[2020-11-14 08:31:35,664 INFO] [PERF]At step 0: rouge1:54.06 rouge2:48.22\n",
            "[2020-11-14 08:31:35,664 INFO] [PERF]MacroPrecision at step 0: P@1:39.90%\tP@2:28.45%\tP@3:18.97%\n",
            "[2020-11-14 08:31:35,664 INFO] [PERF]MicroPrecision at step 0: P@1:39.90%\tP@2:28.45%\tP@3:18.97%\n",
            "1000\n",
            "1000\n",
            "2020-11-14 08:31:35,750 [MainThread  ] [INFO ]  Writing summaries.\n",
            "[2020-11-14 08:31:35,750 INFO] Writing summaries.\n",
            "2020-11-14 08:31:35,750 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmpxzy_twje/system and model files to ../temp/tmpxzy_twje/model.\n",
            "[2020-11-14 08:31:35,750 INFO] Processing summaries. Saving system files to ../temp/tmpxzy_twje/system and model files to ../temp/tmpxzy_twje/model.\n",
            "2020-11-14 08:31:35,750 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2020-11-14-08-31-35/candidate/.\n",
            "[2020-11-14 08:31:35,750 INFO] Processing files in ../temp/rouge-tmp-2020-11-14-08-31-35/candidate/.\n",
            "2020-11-14 08:31:35,839 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmpxzy_twje/system.\n",
            "[2020-11-14 08:31:35,839 INFO] Saved processed files to ../temp/tmpxzy_twje/system.\n",
            "2020-11-14 08:31:35,840 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2020-11-14-08-31-35/reference/.\n",
            "[2020-11-14 08:31:35,840 INFO] Processing files in ../temp/rouge-tmp-2020-11-14-08-31-35/reference/.\n",
            "2020-11-14 08:31:35,923 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmpxzy_twje/model.\n",
            "[2020-11-14 08:31:35,923 INFO] Saved processed files to ../temp/tmpxzy_twje/model.\n",
            "2020-11-14 08:31:36,598 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmpdqq8tos0/rouge_conf.xml\n",
            "[2020-11-14 08:31:36,598 INFO] Written ROUGE configuration to ../temp/tmpdqq8tos0/rouge_conf.xml\n",
            "[2020-11-14 08:31:40,328 INFO] [PERF]Rouges at step 0: RG1-P:42.77\tRG1-R:56.72\tRG1-F:45.16\tRG2-P:20.05\tRG2-R:29.11\tRG2-F:21.83\tRGL-P:42.71\tRGL-R:56.59\tRGL-F:45.08 \n",
            "\n",
            "[2020-11-14 08:31:40,335 INFO] Validation xent: 1.08809 at step 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iOoXUG54pEu"
      },
      "source": [
        "\n",
        "ROUGE Scores are shown here\n",
        "```\n",
        "[2020-11-14 08:31:40,328 INFO] [PERF]Rouges at step 0: RG1-P:42.77\tRG1-R:56.72\tRG1-F:45.16\tRG2-P:20.05\tRG2-R:29.11\tRG2-F:21.83\tRGL-P:42.71\tRGL-R:56.59\tRGL-F:45.08 \n",
        "```\n",
        "Therefore ROUGE-F1 results are:  R1=45.16, R2=21.83, RL=45.08.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAlOcVwj5KNO"
      },
      "source": [
        "## Evaluate by BertScore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l66k5RuG5Vjh"
      },
      "source": [
        "!pip install -q bert_score\n",
        "import bert_score\n",
        "from bert_score import score\n",
        "import logging\n",
        "import transformers\n",
        "transformers.tokenization_utils.logger.setLevel(logging.ERROR)\n",
        "transformers.configuration_utils.logger.setLevel(logging.ERROR)\n",
        "transformers.modeling_utils.logger.setLevel(logging.ERROR)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIrUrZeP5aq4"
      },
      "source": [
        "with open(\"/content/ThaiSum/ARedSum/results/aredsum_base_step0_initial.candidate\") as f: # Output Summary \n",
        "    cands = [line.strip() for line in f]\n",
        "\n",
        "with open(\"/content/ThaiSum/ARedSum/results/aredsum_base_step0_initial.gold\") as f:  # Reference Summary\n",
        "    refs = [line.strip() for line in f]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwB6iIJz5h7G",
        "outputId": "eb1851f0-7051-4741-8599-f55086ede857",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "P, R, F1 = score(cands, refs, lang='th', verbose=False)\n",
        "\n",
        "print(f\"System level F1 score: {F1.mean()*100:.3f}\") ##  *100 to make it simplier to read similar to ROUGE.\n",
        "print(f\"System level P score: {P.mean()*100:.3f}\")\n",
        "print(f\"System level R score: {R.mean()*100:.3f}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1423: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "System level F1 score: 81.076\n",
            "System level P score: 79.806\n",
            "System level R score: 82.700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8La9mENr6BU3",
        "outputId": "ae553ed5-1379-4ab5-a9de-850ef188894d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(F1, bins=20)\n",
        "plt.xlabel(\"score\")\n",
        "plt.ylabel(\"counts\")\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}